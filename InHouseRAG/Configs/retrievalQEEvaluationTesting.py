# Configuration for the retrieval query engine for notion data

RetrievalQEEvaluationTesting = {
    'data_args': {'output_dir': 'DataHouse/Data/notion-ingest-output',
                  'download_dir': 'DataHouse/Data/Unstructured_IO/rawData',
                  'work_dir': 'DataHouse/Data/workDir',
                  'page_ids': ['fb1c47e9cbe54729b5fd0c9330cef866', 'af46eb50845443a993f9a427660243b4'],
                  're_download': True, 'verbose': True, 'recursive': True, 'get_embeddings': False,
                  'embedding_provider': 'langchain-huggingface',
                  'embedding_model_name': 'sentence-transformers/all-MiniLM-L12-v2',
                  'chunking_strategy': 'basic', 'chunk_multipage': True, 'chunk_size': 1000, 'chunk_overlap': 200,
                  'store': 'chroma', 'store_settings': None, 'store_name': 'testCollection'},
    'retriever_args': {'index_type': 'VectorStoreIndex', 'retriever_type': 'VectorIndexRetriever',
                       'create_embeddings': True,
                       'raw_data_dir': 'DataHouse/Data/paul_graham',
                       'embedding_provider': 'langchain-huggingface',
                       'embedding_model_name': 'sentence-transformers/all-MiniLM-L12-v2',
                       'chunk_size': 1024,
                       'chunk_overlap': 200, 'store': 'chroma',
                       'store_settings': {'persistent_path': 'DataHouse/chroma_db',
                                          'collection_name': 'testEvaluationCollection'}},
    'llm_args': {'llm_provider': 'llama-index-huggingface',
                 'llm_model_name': 'meta-llama/Llama-2-7b-chat-hf',
                 'llm_model_path': '/Users/bhargavvankayalapati/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/c1b0db933684edbfe29a06fa47eb19cc48025e93/',
                 'offload_dir': './offload_dir',
                 'cache_dir': '/Users/bhargavvankayalapati/.cache',
                 'local_files_only': True, 'context_window': 4096,
                 'max_new_tokens': 512,
                 'generate_kwargs': {"temperature": 0.7, "top_k": 50, "top_p": 0.95,
                                     'do_sample': False},
                 'tokenizer_max_length': 4096,
                 'stopping_ids': (50278, 50279, 50277, 1, 0),
                 },
    'query_engine_args': {'query_engine_type': 'SubQuestionQueryEngine',
                          'query_engine_kwargs': None,
                          'response_mode': 'compact', 'streaming': True,
                          'text_qa_template_str': None,
                          'refine_template_str': None, 'summary_template_str': None,
                          'simple_template_str': None,
                          'node_postprocessors': None,
                          'callback_manager': None,
                          'use_async': True,
                          'query_engine_tools': {'query_engine': 'RetrieverQueryEngine',
                                                 'metadata': {'name': 'source.txt',
                                                              'description': 'Paul Graham essay on What I Worked On'}}},
    'rag_dataset_generation_args': {'raw_data_dir': 'DataHouse/Data/Unstructured_IO/rawData',
                                    'dataset_name': 'generated-RAG-dataset-notion-nodes',
                                    'questions_per_chunk': 10},
    'evaluation_args': {'project_id': '9500d44e-8059-46a5-9fe1-c4009715644b',
                        'evaluation_dataset': 'Evaluation/paul_graham/rag_dataset.json'}
}
